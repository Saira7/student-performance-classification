{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9c7b87-c602-49e3-ba04-178e575ad53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'rank_uni.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Data Preparation\n",
    "\n",
    "median_score = data['score'].median()\n",
    "data['score_binary'] = (data['score'] >= median_score).astype(int)\n",
    "data['broad_impact'] = data['broad_impact'].fillna(data['broad_impact'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf3cabf-f4a6-4cff-9a70-7c304634847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and target\n",
    "predictors = ['quality_of_education', 'alumni_employment', 'quality_of_faculty',\n",
    "              'publications', 'influence', 'citations', 'broad_impact', 'patents']\n",
    "target = 'score_binary'\n",
    "\n",
    "X = data[predictors]\n",
    "y = data[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19317d8c-8aef-4e07-b6fb-9e8855a1c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"L1 LASSO\": LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    \"L2 Ridge\": LogisticRegression(penalty='l2', solver='lbfgs', random_state=42),\n",
    "    \"Elastic Net\": LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, random_state=42),\n",
    "    \"Support Vector Machine\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC(probability=True, kernel='rbf', random_state=42))\n",
    "    ]),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed95650e-c7eb-4751-a862-5f38be2a8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    brier = brier_score_loss(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return {\n",
    "        \"AUC\": auc,\n",
    "        \"Brier Score\": brier,\n",
    "        \"Precision\": report['1']['precision'],\n",
    "        \"Recall\": report['1']['recall'],\n",
    "        \"F1-Score\": report['1']['f1-score'],\n",
    "        \"Accuracy\": report['accuracy']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f8481d-8cd2-479e-9def-5c4393a6b39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model       AUC  Brier Score  Precision    Recall  \\\n",
      "0     Logistic Regression  0.926724     0.116435   0.776699  0.919540   \n",
      "1                L1 LASSO  0.929075     0.115537   0.784314  0.919540   \n",
      "2                L2 Ridge  0.926724     0.116435   0.776699  0.919540   \n",
      "3             Elastic Net  0.815047     0.176412   0.734940  0.701149   \n",
      "4  Support Vector Machine  0.953501     0.096084   0.792079  0.919540   \n",
      "5           Random Forest  0.981518     0.059050   0.927711  0.885057   \n",
      "\n",
      "   F1-Score  Accuracy  \n",
      "0  0.842105  0.828571  \n",
      "1  0.846561  0.834286  \n",
      "2  0.842105  0.828571  \n",
      "3  0.717647  0.725714  \n",
      "4  0.851064  0.840000  \n",
      "5  0.905882  0.908571  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        results.append({\"Model\": name, **evaluate_model(model, X_train, X_test, y_train, y_test)})\n",
    "    except Exception as e:\n",
    "        results.append({\"Model\": name, \"Error\": str(e)})\n",
    "\n",
    "# Display Results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6791bb9-76e2-412b-949d-5eec1fbe7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.2.13)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (8.1.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (2.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (4.66.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (1.4.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (4.5.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->lazypredict) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->lazypredict) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->lazypredict) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "Using cached scikit_learn-1.5.2-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed scikit-learn-1.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\~~ibs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-uninstall-kvt0ojmb'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-uninstall-b_58gb09'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\~~composition'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\~~ist_gradient_boosting'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\~~ighbors'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade lazypredict scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb522d92-a5b4-4125-8168-a18a56911114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (3.5.0)\n",
      "Using cached scikit_learn-1.0.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "Successfully installed scikit-learn-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39fb8486-e707-4eb5-a37c-ee54c9393c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lazypredict 0.2.13\n",
      "Uninstalling lazypredict-0.2.13:\n",
      "  Successfully uninstalled lazypredict-0.2.13\n",
      "Found existing installation: scikit-learn 1.0.2\n",
      "Uninstalling scikit-learn-1.0.2:\n",
      "  Successfully uninstalled scikit-learn-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y lazypredict scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c08c6318-e220-429f-8e74-18dafd8d6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.2) (3.5.0)\n",
      "Using cached scikit_learn-1.0.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.0.2\n",
      "Collecting lazypredict\n",
      "  Using cached lazypredict-0.2.13-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (8.1.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (1.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (2.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (4.66.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (1.4.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (4.5.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lazypredict) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->lazypredict) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lightgbm->lazypredict) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lightgbm->lazypredict) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->lazypredict) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas->lazypredict) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn->lazypredict) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "Using cached lazypredict-0.2.13-py2.py3-none-any.whl (12 kB)\n",
      "Installing collected packages: lazypredict\n",
      "Successfully installed lazypredict-0.2.13\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2\n",
    "!pip install lazypredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e387ad-325b-4d2a-85db-e6fbb56e0334",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sparse_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlazypredict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSupervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Lazy Predict setup\u001b[39;00m\n\u001b[0;32m      4\u001b[0m lazy_clf \u001b[38;5;241m=\u001b[39m LazyClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, custom_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lazypredict\\Supervised.py:98\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# CLASSIFIERS.append(('CatBoostClassifier',catboost.CatBoostClassifier))\u001b[39;00m\n\u001b[0;32m     91\u001b[0m numeric_transformer \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[0;32m     92\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m\"\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, StandardScaler())]\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m categorical_transformer_low \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[0;32m     96\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     97\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m\"\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m---> 98\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m),\n\u001b[0;32m     99\u001b[0m     ]\n\u001b[0;32m    100\u001b[0m )\n\u001b[0;32m    102\u001b[0m categorical_transformer_high \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[0;32m    103\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    104\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m\"\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     ]\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Helper function\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'sparse_output'"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Lazy Predict setup\n",
    "lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit LazyClassifier on the dataset\n",
    "models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display the results\n",
    "print(\"All Model Results from Lazy Predict:\")\n",
    "print(models)\n",
    "\n",
    "# Filter models with accuracy > 90%\n",
    "high_accuracy_models = models[models['Accuracy'] > 0.90]\n",
    "if not high_accuracy_models.empty:\n",
    "    print(\"\\nModels with Accuracy > 90%:\")\n",
    "    print(high_accuracy_models)\n",
    "else:\n",
    "    print(\"\\nNo additional models with Accuracy > 90% were found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a70add-78ee-463c-a056-737c853263f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for additional classifiers\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# new models to evaluate\n",
    "additional_models = {\n",
    "    \"Bagging Classifier\": BaggingClassifier(random_state=42),\n",
    "    \"Extra Trees Classifier\": ExtraTreesClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(random_state=42),\n",
    "    \"LGBM Classifier\": LGBMClassifier(random_state=42),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42),\n",
    "    \"XGB Classifier\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3a876e1-c384-41ee-99eb-5f845a3b31a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 263, number of negative: 262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 934\n",
      "[LightGBM] [Info] Number of data points in the train set: 525, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500952 -> initscore=0.003810\n",
      "[LightGBM] [Info] Start training from score 0.003810\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "                      Model  AUC  Brier Score  Precision  Recall  F1-Score  \\\n",
      "0        Bagging Classifier 0.99         0.05       0.97    0.89      0.93   \n",
      "1    Extra Trees Classifier 0.98         0.06       0.95    0.89      0.92   \n",
      "2             Random Forest 0.98         0.06       0.93    0.89      0.91   \n",
      "3       AdaBoost Classifier 0.96         0.19       0.94    0.87      0.90   \n",
      "4           LGBM Classifier 0.99         0.06       0.95    0.89      0.92   \n",
      "5  Decision Tree Classifier 0.90         0.10       0.92    0.87      0.89   \n",
      "6            XGB Classifier 0.98         0.07       0.97    0.83      0.89   \n",
      "\n",
      "   Accuracy  \n",
      "0      0.93  \n",
      "1      0.92  \n",
      "2      0.91  \n",
      "3      0.91  \n",
      "4      0.92  \n",
      "5      0.90  \n",
      "6      0.90  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the additional models\n",
    "additional_results = []\n",
    "for name, model in additional_models.items():\n",
    "    try:\n",
    "        additional_results.append({\"Model\": name, **evaluate_model(model, X_train, X_test, y_train, y_test)})\n",
    "    except Exception as e:\n",
    "        additional_results.append({\"Model\": name, \"Error\": str(e)})\n",
    "\n",
    "# Compile results into a DataFrame\n",
    "additional_results_df = pd.DataFrame(additional_results)\n",
    "\n",
    "# Display the results locally\n",
    "print(additional_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04647389-4846-4667-951b-0a9e907682a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
